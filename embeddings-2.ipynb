{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62d47c-1aec-43d2-a202-e22946a4e21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b63a72fe-1eb0-4272-a503-43887c559902",
   "metadata": {},
   "source": [
    "## Training an embedding model\n",
    "\n",
    "Let's try contrastive learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d085c85-bdce-4d33-abc7-99d09170380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chang/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "target_model = SentenceTransformer(\"quora-distilbert-multilingual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7f595-7777-4e28-90cb-2948e1a55ee0",
   "metadata": {},
   "source": [
    "Dataset to train: Quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d1d06f-474d-4717-9b6d-b89b2cee8540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['questions', 'is_duplicate'],\n",
       "    num_rows: 404290\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"quora\", trust_remote_code=True)[\"train\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "357525b1-3d17-4115-9ccb-3fbd33441dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537362\n"
     ]
    }
   ],
   "source": [
    "# Collect all the questions, then deduplicate\n",
    "corpus_questions = []\n",
    "for d in dataset:\n",
    "    corpus_questions.append(d[\"questions\"][\"text\"][0])\n",
    "    corpus_questions.append(d[\"questions\"][\"text\"][1])\n",
    "corpus_questions = list(set(corpus_questions))  # Remove duplicates\n",
    "print(len(corpus_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0380c3d8-e95d-41ea-af14-869e224c69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_to_embed = 10_000\n",
    "\n",
    "target_embeddings = target_model.encode(\n",
    "    corpus_questions[:questions_to_embed],\n",
    "    # show_progress_bar=True,\n",
    "    convert_to_tensor=True,\n",
    ")\n",
    "\n",
    "current_embeddings = model.encode(\n",
    "    corpus_questions[:questions_to_embed],\n",
    "    # show_progress_bar=True,\n",
    "    convert_to_tensor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25022d41-eb10-4f2b-9954-c55aaa235850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 768])\n",
      "torch.Size([10000, 384])\n"
     ]
    }
   ],
   "source": [
    "print(target_embeddings.shape)\n",
    "print(current_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95bedf06-706c-451d-942c-b7c1e1df27df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def search(query, model, embeddings, n=5, show=True):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    results = util.semantic_search(query_embedding, embeddings, top_k=n) # this uses cosine similarity\n",
    "\n",
    "    # We look at top n results\n",
    "    if show:\n",
    "        for result in results[0][:n]:\n",
    "            print(\n",
    "                \"{:.3f}\\t{}\".format(result[\"score\"], corpus_questions[result[\"corpus_id\"]])\n",
    "            )\n",
    "    return results[0][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f207865-4267-4824-8194-612c0d1995f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961\tWhat is the best way to learn Python and django?\n",
      "0.949\tHow do I run Python Code on Sublime Text 3?\n",
      "0.949\tHow can I run Python 2.7 code if I have Python 3.4 installed?\n",
      "0.948\tWhere do I learn python in Mumbai?\n",
      "0.944\tHow can I learn to write idiomatic Python?\n",
      "0.942\tHow long does it take to learn the basics of Python before you can do anything fun/interesting?\n",
      "0.936\tHow is Python being used at Facebook?\n",
      "0.928\tWhich is the best book to learn Python?\n",
      "0.926\tShould I learn c++ or Java before learning Python?\n",
      "0.926\tWhat is best book to learn GUI programming with Python?\n"
     ]
    }
   ],
   "source": [
    "python_query = \"How can I learn Python online?\"\n",
    "search(python_query, target_model, target_embeddings, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5de9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.744\tWhich is the best books or online courses for learning python from basic to advanced?\n",
      "0.647\tWhich is the best book to learn Python?\n",
      "0.628\tWhat is the best way to learn Python and django?\n",
      "0.615\tWhere do I learn python in Mumbai?\n",
      "0.597\tHow long does it take to learn the basics of Python before you can do anything fun/interesting?\n",
      "0.581\tHow can I learn to write idiomatic Python?\n",
      "0.559\tWhat is best book to learn GUI programming with Python?\n",
      "0.559\tHow do I learn programming for free?\n",
      "0.521\tShould I learn c++ or Java before learning Python?\n",
      "0.512\tWhat is the best place to learn Spanish online?\n"
     ]
    }
   ],
   "source": [
    "search(python_query, model, current_embeddings, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2383202c",
   "metadata": {},
   "source": [
    "Observations: \n",
    "\n",
    "- the target model has a much \"higher\" score in the top 5\n",
    "- difference in questions returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3bc601",
   "metadata": {},
   "source": [
    "### Building a dataset to train\n",
    "\n",
    "We want to build a contrastive learning dataset.\n",
    "\n",
    "Can we actually \"move the needle?\"\n",
    "\n",
    "Example dataset: https://huggingface.co/datasets/sentence-transformers/all-nli\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7b3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_nli_dataset = load_dataset(\"sentence-transformers/all-nli\", \"triplet\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2154b4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['anchor', 'positive', 'negative'],\n",
      "    num_rows: 557850\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(sample_nli_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bafab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'A person on a horse jumps over a broken down airplane.',\n",
       " 'positive': 'A person is outdoors, on a horse.',\n",
       " 'negative': 'A person is at a diner, ordering an omelette.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_nli_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fe519",
   "metadata": {},
   "source": [
    "Let's think of this as `query`, `good answer`, `bad answer` and use this to construct a toy example on the Quora dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 1000 examples [00:35, 28.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "train_data_size = 1_000\n",
    "# train_data_size = 100\n",
    "queries = corpus_questions[questions_to_embed:questions_to_embed+train_data_size]\n",
    "\n",
    "\n",
    "def build_example_from_query(query, n=5):\n",
    "    # search and return top 5 from target and current models\n",
    "    target_results = search(query, target_model, target_embeddings, n, show=False)\n",
    "    current_results = search(query, model, current_embeddings, n, show=False)\n",
    "    # take the last one from current results and pair with the first one with target results\n",
    "    most_positive = target_results[0][\"corpus_id\"]\n",
    "    most_negative = current_results[n-1][\"corpus_id\"]\n",
    "    return {\n",
    "        \"anchor\": query,\n",
    "        \"positive\": corpus_questions[most_positive],\n",
    "        \"negative\": corpus_questions[most_negative],\n",
    "    }\n",
    "\n",
    "# Build a training dataset with huggingface Dataset\n",
    "\n",
    "def gen():\n",
    "    for query in queries:\n",
    "        yield build_example_from_query(query)\n",
    "        \n",
    "quora_train_ds = ds = Dataset.from_generator(gen)\n",
    "\n",
    "\n",
    "# train_data = []\n",
    "# # takes 40s on Mac\n",
    "# for query in queries:\n",
    "#     triplet = build_example_from_query(query)\n",
    "#     train_data.append(triplet)\n",
    "#     # print(triplet)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f50009f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'Was Um Bongo ever available in the Congo?',\n",
       " 'positive': 'What is Mongoose?',\n",
       " 'negative': 'Does Brazil have a special economic zone?'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_train_ds[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d063062c",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "With triplet loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d7286d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f5d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "loss = losses.TripletLoss(model=model)\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=quora_train_ds,\n",
    "    loss=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7ffb649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=4.7815302734375, metrics={'train_runtime': 89.1778, 'train_samples_per_second': 33.641, 'train_steps_per_second': 4.205, 'total_flos': 0.0, 'train_loss': 4.7815302734375, 'epoch': 3.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca72f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=\"./finetuned-quora-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb736b5",
   "metadata": {},
   "source": [
    "Did we change the behavior of the model??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28ef5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = SentenceTransformer(\"./finetuned-quora-model\")\n",
    "og_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "737d5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embeddings = trained_model.encode(\n",
    "    corpus_questions[:questions_to_embed],\n",
    "    # show_progress_bar=True,\n",
    "    convert_to_tensor=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c57d8dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.961\tWhat is the best way to learn Python and django?\n",
      "0.949\tHow do I run Python Code on Sublime Text 3?\n",
      "0.949\tHow can I run Python 2.7 code if I have Python 3.4 installed?\n",
      "0.948\tWhere do I learn python in Mumbai?\n",
      "0.944\tHow can I learn to write idiomatic Python?\n",
      "---------------------------------------------------------\n",
      "0.662\tWhich is the best book to learn Python?\n",
      "0.635\tWhich is the best books or online courses for learning python from basic to advanced?\n",
      "0.602\tHow long does it take to learn the basics of Python before you can do anything fun/interesting?\n",
      "0.602\tWhat is the best way to learn Python and django?\n",
      "0.598\tHow do I install a python program on a random PC?\n",
      "---------------------------------------------------------\n",
      "0.978\tHow can I learn to write idiomatic Python?\n",
      "0.978\tHow long does it take to learn the basics of Python before you can do anything fun/interesting?\n",
      "0.975\tWhich is the best books or online courses for learning python from basic to advanced?\n",
      "0.975\tWhich is the best book to learn Python?\n",
      "0.962\tWhat default modules come with Python?\n"
     ]
    }
   ],
   "source": [
    "# compare some examples\n",
    "python_query = \"How can I learn Python online?\"\n",
    "_ = search(python_query, target_model, target_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(python_query, model, current_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(python_query, trained_model, new_embeddings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "faa17829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What u all think giving a bunch of assignments to complete in engineering is worthful.if not, then why it is not stopped yet?\n",
      "---------------------------------------------------------\n",
      "0.935\tWhat are the best part time jobs while doing engineering?\n",
      "0.934\tI am having trouble getting a job in the Mechanical Engineering field.  My resume‚Äô is excellent.  My interviewing I have been told is ‚Äúvery good‚Äù.  My references are good.  I had my resume‚Äô professionally done.  Should I get a Masters?\n",
      "0.930\tI am 25 years old and still not finished my engineering degree. I still two more years remaining. What should I do?\n",
      "0.928\tHi Ashwin, I wish to apply for masters in mechanical Engineering management. Will work experience play an important role?\n",
      "0.922\tWhich is better, mechanical or computer science engineering in terms of jobs after graduation?\n",
      "---------------------------------------------------------\n",
      "0.579\tWhy are Germans so good at engineering?\n",
      "0.575\tWhat happens when we complete engineering in 5 years?\n",
      "0.560\tShould I become an engineer?\n",
      "0.537\tShould I quit engineering?\n",
      "0.537\tHow is the world without engineers?\n",
      "---------------------------------------------------------\n",
      "0.921\tWhat happens when we complete engineering in 5 years?\n",
      "0.914\tWhat are the best part time jobs while doing engineering?\n",
      "0.911\tWhat are some of the best engineering job consultancies in India?\n",
      "0.909\tWhat are good research topics on engineering project?\n",
      "0.890\tI am 25 years old and still not finished my engineering degree. I still two more years remaining. What should I do?\n"
     ]
    }
   ],
   "source": [
    "query = corpus_questions[200001]\n",
    "print(f'{query}')\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(query, target_model, target_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(query, model, current_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(query, trained_model, new_embeddings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d260613e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a SaaS company?\n",
      "---------------------------------------------------------\n",
      "0.907\tWhat is the typical revenue per employee for a B2B SaaS company?\n",
      "0.887\tHow do I validate SaaS idea?\n",
      "0.887\tWhat is DaaS?\n",
      "0.878\tWho are some of the leading local IaaS cloud service providers in India?\n",
      "0.866\tWhat are good product companies where SAP ABAP/SAP HCM jobs are there?\n",
      "---------------------------------------------------------\n",
      "0.561\tWhat's the difference between SaaS and the Cloud?\n",
      "0.528\tHow do I validate SaaS idea?\n",
      "0.388\tWhat are un, saarc, oecd?\n",
      "0.316\tWhat are the commonly used final gear ratios and tyre size combinations for supra sae cars for a 43 bhp KTM engine?\n",
      "0.305\tWhat is the typical revenue per employee for a B2B SaaS company?\n",
      "---------------------------------------------------------\n",
      "0.978\tHow do I validate SaaS idea?\n",
      "0.958\tWhat is the typical revenue per employee for a B2B SaaS company?\n",
      "0.532\tWhat's the difference between SaaS and the Cloud?\n",
      "0.464\tHow is South Africa's economy doing in 2014?\n",
      "0.429\tWhat should be the job preference in SSC CGL 2016, if I want to prepare for civil services?\n"
     ]
    }
   ],
   "source": [
    "query = corpus_questions[300_007]\n",
    "print(f'{query}')\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(query, target_model, target_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(query, model, current_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "_ = search(query, trained_model, new_embeddings, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d3970",
   "metadata": {},
   "source": [
    "Still a long way to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1e17c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 45.96ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "189021"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_train_ds.to_csv('./data/quora-own-dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0ba09b",
   "metadata": {},
   "source": [
    "I am building a contrastive learning dataset with TripletLoss. As such, I must determine the quality of each record of data. Can you tell me if this is a good triplet for my dataset or it's way off?\n",
    "\n",
    "{'anchor': 'What are differences between IELTS and IELTS for ukvi?', 'positive': 'How are Verilog-A and Verilog-AMS utilized in the industry?', 'negative': 'Can I crack IELTS exam without coaching?'}\n",
    "\n",
    "\n",
    "response:\n",
    "\n",
    "```\n",
    "This triplet is way off for a contrastive learning dataset using TripletLoss.\n",
    "\n",
    "Let's break it down:\n",
    "\n",
    "‚úÖ What Makes a Good Triplet?\n",
    "A good triplet follows this structure:\n",
    "\n",
    "Anchor: A sample query or data point.\n",
    "Positive: A sample that is semantically similar to the anchor (close in the latent space).\n",
    "Negative: A sample that is semantically different from the anchor (far in the latent space).\n",
    "What I See in Your Triplet:\n",
    "Element\tContent\tQuality\n",
    "Anchor\tWhat are differences between IELTS and IELTS for ukvi?\tQuestion about IELTS exam types\n",
    "Positive\tHow are Verilog-A and Verilog-AMS utilized in the industry?\tüö´ Completely unrelated (electronics design languages vs IELTS)\n",
    "Negative\tCan I crack IELTS exam without coaching?\tüö´ This is too close to the anchor (both are about IELTS exams ‚Äî it could confuse the model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cca42",
   "metadata": {},
   "source": [
    "## Evaluating embeddings model\n",
    "\n",
    "torchmetrics <-- this looks promising\n",
    "\n",
    "Perplexity query https://www.perplexity.ai/search/is-there-a-python-package-that-CHyy87UMRnWGhzNQ4lRbmA\n",
    "\n",
    "```py\n",
    "from torchmetrics.retrieval import RetrievalMRR\n",
    "import torch\n",
    "\n",
    "indexes = torch.tensor([0, 0, 0, 1, 1, 1, 1])\n",
    "preds = torch.tensor([0.2, 0.3, 0.5, 0.1, 0.3, 0.5, 0.2])\n",
    "target = torch.tensor([False, False, True, False, True, False, True])\n",
    "\n",
    "mrr = RetrievalMRR()\n",
    "mrr(preds, target, indexes=indexes)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8dc0d",
   "metadata": {},
   "source": [
    "MRR: if all we care is \"are the correct ones in and are they in the higher positions?\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "401014e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907\tWhat is the typical revenue per employee for a B2B SaaS company?\n",
      "0.887\tHow do I validate SaaS idea?\n",
      "0.887\tWhat is DaaS?\n",
      "0.878\tWho are some of the leading local IaaS cloud service providers in India?\n",
      "0.866\tWhat are good product companies where SAP ABAP/SAP HCM jobs are there?\n",
      "---------------------------------------------------------\n",
      "0.561\tWhat's the difference between SaaS and the Cloud?\n",
      "0.528\tHow do I validate SaaS idea?\n",
      "0.388\tWhat are un, saarc, oecd?\n",
      "0.316\tWhat are the commonly used final gear ratios and tyre size combinations for supra sae cars for a 43 bhp KTM engine?\n",
      "0.305\tWhat is the typical revenue per employee for a B2B SaaS company?\n",
      "---------------------------------------------------------\n",
      "0.978\tHow do I validate SaaS idea?\n",
      "0.958\tWhat is the typical revenue per employee for a B2B SaaS company?\n",
      "0.532\tWhat's the difference between SaaS and the Cloud?\n",
      "0.464\tHow is South Africa's economy doing in 2014?\n",
      "0.429\tWhat should be the job preference in SSC CGL 2016, if I want to prepare for civil services?\n"
     ]
    }
   ],
   "source": [
    "target_results = search(query, target_model, target_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "current_results = search(query, model, current_embeddings, 5)\n",
    "print('---------------------------------------------------------')\n",
    "new_results = search(query, trained_model, new_embeddings, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "658c6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_rank(results):\n",
    "    return [r[\"corpus_id\"] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ded7e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 7107, 'score': 0.560981810092926},\n",
       " {'corpus_id': 5293, 'score': 0.5279558897018433},\n",
       " {'corpus_id': 9441, 'score': 0.3883669078350067},\n",
       " {'corpus_id': 1864, 'score': 0.31555840373039246},\n",
       " {'corpus_id': 1086, 'score': 0.30493882298469543}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_results\n",
    "# [{'corpus_id': 1086, 'score': 0.9072297811508179},\n",
    "#  {'corpus_id': 5293, 'score': 0.8874691724777222},\n",
    "#  {'corpus_id': 9711, 'score': 0.8872179985046387},\n",
    "#  {'corpus_id': 6128, 'score': 0.8783174753189087},\n",
    "#  {'corpus_id': 7710, 'score': 0.8664107322692871}]\n",
    "current_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4fe59ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ranking = [_[\"corpus_id\"] for _ in target_results]\n",
    "current_ranking = [_[\"corpus_id\"] for _ in current_results]\n",
    "new_ranking = [_[\"corpus_id\"] for _ in new_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21eb3e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1086, 5293, 9711, 6128, 7710]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6dea04fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7107, 5293, 9441, 1864, 1086]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8fc5df3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank(pred, target):\n",
    "    \n",
    "    assert len(pred) == len(target)\n",
    "    \n",
    "    target = set(target)\n",
    "    for rank, id in enumerate(pred):\n",
    "        if id in target:\n",
    "            return 1 / (rank + 1)\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "edba1cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(reciprocal_rank(current_ranking, target_ranking))\n",
    "print(reciprocal_rank(new_ranking, target_ranking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dc80f1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR before training: 0.4378333333333334\n",
      "MRR after training: 0.5060000000000001\n"
     ]
    }
   ],
   "source": [
    "# run this with 100 examples\n",
    "start_position = 300_000\n",
    "test_set_size = 100\n",
    "\n",
    "mrr_untrained_sum = 0\n",
    "mrr_trained_sum = 0\n",
    "\n",
    "for query in corpus_questions[start_position:start_position+test_set_size]:\n",
    "    target_rank = result_rank(search(query, target_model, target_embeddings, 5, show=False))\n",
    "    untrained_rank = result_rank(search(query, model, current_embeddings, 5, show=False))\n",
    "    trained_rank = result_rank(search(query, trained_model, new_embeddings, 5, show=False))\n",
    "    \n",
    "    mrr_untrained_sum += reciprocal_rank(untrained_rank, target_rank)\n",
    "    mrr_trained_sum += reciprocal_rank(trained_rank, target_rank)\n",
    "    \n",
    "mrr_untrained = mrr_untrained_sum / test_set_size\n",
    "mrr_trained = mrr_trained_sum / test_set_size\n",
    "\n",
    "print(f'MRR before training: {mrr_untrained}')\n",
    "print(f'MRR after training: {mrr_trained}')    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953d15e",
   "metadata": {},
   "source": [
    "Another metric: nDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f93478",
   "metadata": {},
   "source": [
    "## Train again with smaller learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4aaa4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "\n",
    "bs = 64\n",
    "lr = 2e-5\n",
    "epochs=4\n",
    "\n",
    "# I used args from fast.ai's course\n",
    "# https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners\n",
    "\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"./finetuned-quora-model-run-2\",\n",
    "    num_train_epochs=epochs,\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=bs,\n",
    "    per_device_eval_batch_size=bs*2,\n",
    "    weight_decay=0.01,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    "    # warmup in deep learning: https://datascience.stackexchange.com/questions/55991/in-the-context-of-deep-learning-what-is-training-warmup-steps\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type='cosine',\n",
    "    # fp16=True,\n",
    "    # log_level=\"error\",\n",
    "    # report_to='none',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9b40076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chang/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:125: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "User specified an unsupported autocast device_type 'mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m losses\u001b[38;5;241m.\u001b[39mTripletLoss(model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mquora_train_ds,\n\u001b[1;32m      6\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[1;32m      7\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/transformers/trainer.py:2365\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2363\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2365\u001b[0m         model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;66;03m# to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m     model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mprepare(\n\u001b[1;32m   2369\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\n\u001b[1;32m   2370\u001b[0m     )\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/accelerate/accelerator.py:1227\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[38;5;66;03m# MS-AMP will handle the device placement\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m         device_placement \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m-> 1227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_one(obj, device_placement\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu_should_fix_optimizer \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp8\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp8_recipe_handler\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTE\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;66;03m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/accelerate/accelerator.py:1228\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[38;5;66;03m# MS-AMP will handle the device placement\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m         device_placement \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m   1227\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m-> 1228\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, device_placement)\n\u001b[1;32m   1229\u001b[0m     )\n\u001b[1;32m   1230\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_one(obj, device_placement\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu_should_fix_optimizer \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp8\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp8_recipe_handler\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTE\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;66;03m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/accelerate/accelerator.py:1104\u001b[0m, in \u001b[0;36mAccelerator._prepare_one\u001b[0;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data_loader(obj, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m-> 1104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_placement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer):\n\u001b[1;32m   1106\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_optimizer(obj, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/accelerate/accelerator.py:1294\u001b[0m, in \u001b[0;36mAccelerator.prepare_model\u001b[0;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[1;32m   1292\u001b[0m model\u001b[38;5;241m.\u001b[39m_original_forward \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward\n\u001b[1;32m   1293\u001b[0m model_forward_func \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39mforward, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__func__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mforward\n\u001b[0;32m-> 1294\u001b[0m autocast_context \u001b[38;5;241m=\u001b[39m \u001b[43mget_mixed_precision_context_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m new_forward \u001b[38;5;241m=\u001b[39m autocast_context(model_forward_func)\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model\u001b[38;5;241m.\u001b[39mforward, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__func__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/accelerate/utils/modeling.py:1590\u001b[0m, in \u001b[0;36mget_mixed_precision_context_manager\u001b[0;34m(native_amp, autocast_kwargs)\u001b[0m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m native_amp:\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1590\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mautocast_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmixed_precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbf16\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m   1592\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mNO,\n\u001b[1;32m   1593\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mMULTI_CPU,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1597\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mFSDP,\n\u001b[1;32m   1598\u001b[0m     ]:\n\u001b[1;32m   1599\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39mstate\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mautocast_kwargs)\n",
      "File \u001b[0;32m~/projects/uncc-2024-6188/.venv/lib/python3.9/site-packages/torch/amp/autocast_mode.py:241\u001b[0m, in \u001b[0;36mautocast.__init__\u001b[0;34m(self, device_type, dtype, enabled, cache_enabled)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfast_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_device_mod\u001b[38;5;241m.\u001b[39mget_autocast_dtype()\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser specified an unsupported autocast device_type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    246\u001b[0m     enabled\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39mamp_definitely_not_available()\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m ):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: User specified an unsupported autocast device_type 'mps'"
     ]
    }
   ],
   "source": [
    "mode2 = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "loss = losses.TripletLoss(model=model)\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=quora_train_ds,\n",
    "    loss=loss,\n",
    "    args=training_args\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c0f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f60c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c14138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f39f5b8",
   "metadata": {},
   "source": [
    "TODO - Use 1 eval metric to compare before and after training. Does it get better? Does it get better with more data?\n",
    "\n",
    "Explanation of relevance metrics\n",
    "\n",
    "Set up for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c45dd4f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
